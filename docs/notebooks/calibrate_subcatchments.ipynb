{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Cascaded calibration of subcatchments defined by multiple gauges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from swift2.doc_helper import pkg_versions_info\n",
    "\n",
    "print(pkg_versions_info(\"This document was generated from a jupyter notebook\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Use case\n",
    "\n",
    "**2021-01: this vignette works structurally, but is confined to overly short (and possibly difficult) data to keep runtime low**\n",
    "\n",
    "This vignette demonstrates how one can calibrate a catchment using multiple gauging points available within this catchment. Instead of setting up a whole-of-catchment calibration definition, it makes sense, at least in a system where subareas above a gauge points do not have a behavior dependent on other catchment processes (meaning mostly, no managed reservoirs). SWIFT offers capabilities to calibrate such subcatchments sequentially, feeding the input flow of upstream and already calibrated subcatchments to other subcatchments, thus cutting down on the complexity and runtime of the overall catchment calibration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import swift2.doc_helper as std\n",
    "import swift2.parameteriser as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cinterop.timeseries import xr_ts_end, xr_ts_start\n",
    "from swift2.classes import CompositeParameteriser, ObjectiveEvaluator, Simulation\n",
    "from swift2.const import CATCHMENT_FLOWRATE_VARID\n",
    "from swift2.vis import plot_two_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data\n",
    "\n",
    "The sample data that comes with the package contains a model definition for the South Esk catchment, including a short subset of the climate and flow record data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'GR4J'\n",
    "site_id = 'South_Esk'\n",
    "simulation = std.sample_catchment_model(site_id=site_id, config_id='catchment')\n",
    "simulation = simulation.swap_model('LagAndRoute', 'channel_routing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "A visual of the catchment structure (note: may not render yet through GitHub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import swift2.wrap.swift_wrap_generated as swg\n",
    "# dot_graph = swg.GetCatchmentDOTGraph_py(simulation)\n",
    "# import graphviz\n",
    "# # Using graphviz package directly\n",
    "# graph = graphviz.Source(dot_graph)\n",
    "# graph  # This will display the graph in a Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other possible visualisation resources:\n",
    "# https://towardsdatascience.com/visualizing-networks-in-python-d70f4cbeb259\n",
    "# https://medium.com/@ludvig.hult/drawing-graphs-with-python-in-2019-bdd42bf9d5db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loadSwiftV1TextDef(controlFile, dataDir):\n",
    "#     import swift2.wrap.swift_wrap_generated as swg\n",
    "#     # controlFile = mkPathToPlatform(controlFile)\n",
    "#     # dataDir = mkPathToPlatform(dataDir)\n",
    "#     return swg.LoadVersionOneControlFile_py(controlFile, dataDir)\n",
    "\n",
    "\n",
    "# ctrl_file = '/home/per202/mnt/hydrofct/work/common/Staff/per202/sample_data/South_Esk/201601/SWIFT_Control.txt')\n",
    "# stopifnot(file.exists(ctrl_file))\n",
    "# ms <- loadSwiftV1TextDef(ctrl_file, 'dummy')\n",
    "# ms <- swapModel(ms, 'MuskingumNonLinear', 'channel_routing')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "se_climate = std.sample_series(site_id=site_id, var_name='climate')\n",
    "se_flows = std.sample_series(site_id=site_id, var_name='flow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "se_climate[\"subcatchment.4.P\"].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "The names of the climate series is already set to the climate input identifiers of the model simulation, so setting them as inputs is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "se_climate.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation.play_input(se_climate)\n",
    "simulation.set_simulation_span(xr_ts_start(se_climate), xr_ts_end(se_climate))\n",
    "simulation.set_simulation_time_step('hourly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "The `doc_helper` submodule has helper functions to configure the gr4j model to such that it is fit to run on hourly data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "std.configure_hourly_gr4j(simulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Parameterisation\n",
    "\n",
    "We define a function creating a realistic feasible parameter space. This is not the main object of this vignette, so we do not describe in details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import swift2.helpers as hlp\n",
    "import swift2.parameteriser as sp\n",
    "from swift2.utils import as_xarray_series, c, paste0, rep\n",
    "\n",
    "def create_meta_parameteriser(simulation:Simulation, ref_area=250, time_span=3600):  \n",
    "    time_span = int(time_span)\n",
    "    parameteriser = std.define_gr4j_scaled_parameter(ref_area, time_span)\n",
    "  \n",
    "    # Let's define _S0_ and _R0_ parameters such that for each GR4J model instance, _S = S0 * x1_ and _R = R0 * x3_\n",
    "    p_states = sp.linear_parameteriser(\n",
    "                      param_name=c(\"S0\",\"R0\"), \n",
    "                      state_name=c(\"S\",\"R\"), \n",
    "                      scaling_var_name=c(\"x1\",\"x3\"),\n",
    "                      min_p_val=c(0.0,0.0), \n",
    "                      max_p_val=c(1.0,1.0), \n",
    "                      value=c(0.9,0.9), \n",
    "                      selector_type='each subarea')\n",
    "  \n",
    "    init_parameteriser = p_states.make_state_init_parameteriser()\n",
    "    parameteriser = sp.concatenate_parameterisers(parameteriser, init_parameteriser)\n",
    "    \n",
    "    hlp.lag_and_route_linear_storage_type(simulation)\n",
    "    hlp.set_reach_lengths_lag_n_route(simulation)\n",
    "\n",
    "    lnrp = hlp.parameteriser_lag_and_route()\n",
    "    parameteriser = CompositeParameteriser.concatenate(parameteriser, lnrp, strategy='')\n",
    "    return parameteriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameteriser = create_meta_parameteriser(simulation)\n",
    "parameteriser.as_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Now, checking that a default parameter set works structurally on the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameteriser.set_parameter_value('asinh_x2', 0)\n",
    "parameteriser.apply_sys_config(simulation)\n",
    "simulation.exec_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "We are now ready to enter the main topic of this vignette, subsetting the catchment into subcatchments for calibration purposes.\n",
    "\n",
    "## Splitting the catchment in subcatchments\n",
    "\n",
    "The sample gauge data flow contains identifiers that are of course distinct from the network node identifiers. We create a map between them (note - this information used to be in the NodeLink file in swiftv1), and we use these node as splitting points to derive subcatchments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauges = c( '92106', '592002', '18311', '93044',    '25',   '181')\n",
    "node_ids = paste0('node.', c('7',   '12',   '25',   '30',   '40',   '43'))\n",
    "node_gauges = OrderedDict([(node_ids[i], gauges[i]) for i in range(len(gauges))])\n",
    "# names(gauges) = node_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Test running and recording streamflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation.get_variable_ids(node_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation.record_state(paste0(node_ids, \".OutflowRate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "simulation.exec_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled = simulation.get_all_recorded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled.sel(variable_identifiers='node.7.OutflowRate').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "se_flows[gauges[3]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_multivariate_time_series(df, cols_wrap=3):\n",
    "    \"\"\"\n",
    "    Plots all columns of a Pandas DataFrame (time series) in a grid using Seaborn.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with a DatetimeIndex.\n",
    "        cols_wrap (int): Number of columns in the grid.  Defaults to 3.\n",
    "    \"\"\"\n",
    "\n",
    "    num_cols = len(df.columns)\n",
    "    num_rows = (num_cols + cols_wrap - 1) // cols_wrap  # Calculate number of rows needed\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, cols_wrap, figsize=(15, 5 * num_rows)) # Adjust figure size as needed\n",
    "    axes = axes.flatten()  # Flatten the axes array for easy indexing\n",
    "\n",
    "    for i, col in enumerate(df.columns):\n",
    "        sns.lineplot(x=df.index, y=df[col], ax=axes[i])\n",
    "        axes[i].set_title(col)\n",
    "        axes[i].tick_params(axis='x', rotation=45)  # Rotate x-axis labels for readability\n",
    "\n",
    "    # Remove any unused subplots\n",
    "    for i in range(num_cols, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to prevent overlapping titles/labels\n",
    "    plt.show()\n",
    "\n",
    "# Example usage (assuming you have a DataFrame called 'se_flows')\n",
    "plot_multivariate_time_series(se_flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_element_ids = node_ids\n",
    "sub_cats = simulation.split_to_subcatchments(split_element_ids)\n",
    "sub_cats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "The resulting list of subcatchment simulations is already ordered in an upstream to downstream order by SWIFT.\n",
    "\n",
    "If we are to set up the first step of the sequential calibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_cats['node.40'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def first(d:OrderedDict):\n",
    "    return list(sub_cats.items())[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "element_id = first(sub_cats)[0]\n",
    "element_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "gaugeId = node_gauges[element_id]\n",
    "gaugeId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "gauge_flow = se_flows[[gaugeId]]\n",
    "gauge_flow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "sc = sub_cats[element_id]\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "parameteriser.apply_sys_config(sc)\n",
    "var_id = CATCHMENT_FLOWRATE_VARID\n",
    "sc.record_state(var_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DiagrammeR(getCatchmentDotGraph(sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Let's view the default, uncalibrated output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation.get_simulation_span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_obs_vs_calc(obs, calc, ylab=\"streamflow (m3/s)\"):\n",
    "    plot_two_series(obs, calc, start_time = xr_ts_start(obs), end_time = xr_ts_end(obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge_flow = as_xarray_series(gauge_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.exec_simulation()\n",
    "plot_obs_vs_calc(gauge_flow, sc.get_recorded(var_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "Now, setting up an objective (NSE) and optimiser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "objectiveId = 'NSE'\n",
    "objective = sc.create_objective(var_id, gauge_flow, objectiveId, xr_ts_start(se_flows), xr_ts_end(se_flows))\n",
    "score = objective.get_score(parameteriser)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# termination = getMarginalTermination( tolerance = 1e-04, cutoff_no_improvement = 30, max_hours = 2/60) \n",
    "termination = sp.create_sce_termination_wila('relative standard deviation', c('0.05','0.0167'))\n",
    "sce_params = sp.get_default_sce_parameters()\n",
    "params = parameteriser.as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(abs(params.Max-params.Min)>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "npars = np.count_nonzero(abs(params.Max-params.Min)>0)\n",
    "sce_params = std.sce_parameter(npars)\n",
    "optimiser = objective.create_sce_optim_swift(termination_criterion = termination, population_initialiser = parameteriser,sce_params = sce_params)\n",
    "calib_logger = optimiser.set_calibration_logger(\"dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calib_results = optimiser.execute_optimisation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "And the resulting hydrograph follows. The NSE score is decent, but the magnitude of the peak is not well represented. We used a uniform value for the routing parameters; having a scaling based on link properties may be a line of enquiry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_results = calib_results.sort_by_score('NSE')\n",
    "d = sorted_results.as_dataframe()\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sorted_results.get_parameters_at_index(1)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.apply_sys_config(sc)\n",
    "sc.exec_simulation()\n",
    "plot_obs_vs_calc(gauge_flow, sc.get_recorded(var_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "We can create a subcatchment parameteriser, such that when applied to the whole of the South Esk, only the states of the subareas, links and nodes of the subcatchment are potentially affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = p.subcatchment_parameteriser(sc)\n",
    "sp.apply_sys_config(simulation)\n",
    "simulation.get_state_value(paste0('subarea.', np.arange(34,stop=41), '.x2'))\n",
    "# saIds = get_subarea_ids(simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# spFile = tempfile()\n",
    "# SaveParameterizer_R(sp, spFile)\n",
    "# # Following fails 2020-06, see https://jira.csiro.au/browse/WIRADA-631 \n",
    "# # sp2 = LoadParameterizer_R(spFile)\n",
    "\n",
    "# if(file.exists(spFile)) { file.remove(spFile) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {
    "eval": false,
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "p = sorted_results.get_parameters_at_index(1)\n",
    "p.as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {
    "eval": false,
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# swoop(sc, p, param_name, from, to, num=10, var_id) {\n",
    "#   if(missing(from)) { from = GetParameterMinValue_R(p, param_name)}\n",
    "#   if(missing(to))   { to = GetParameterMaxValue_R(p, param_name)}\n",
    "#   oat(sc, p, param_name, from=from, to=to, num=num, var_id) \n",
    "# }\n",
    "\n",
    "# testp(sim, p, ...) {\n",
    "#   q = CloneHypercubeParameterizer_R(p)\n",
    "#   execSimulation(sim)\n",
    "#   params = list(...)\n",
    "#   for(pname in names(params)) {set_parameter_value(q, pname, params[[pname]])}\n",
    "#   plot_obs_vs_calc(gaugeFlow, getRecorded(sim, var_id))\n",
    "# }\n",
    "\n",
    "# flows = swoop(sc, p, 'log_x4', var_id=var_id)\n",
    "\n",
    "# flows = swoop('log_x1')\n",
    "# flows = swoop('Alpha')\n",
    "# flows = merge(flows, gaugeFlow)\n",
    "# zoo::plot.zoo(flows, plot.type='single')\n",
    "# col=c('orange', 'black','blue','red')\n",
    "\n",
    "# f(...) {\n",
    "# params = list(...)\n",
    "# params\n",
    "# set_parameter_value(p, names(params), as.numeric(params))\n",
    "# applySysConfig(p, sc)\n",
    "# execSimulation(sc)\n",
    "# plot_obs_vs_calc(gaugeFlow, getRecorded(sc, var_id))\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "## Whole of catchment calibration combining point gauges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauges = c( '92106', '592002', '18311', '93044',    '25',   '181')\n",
    "node_ids = paste0('node.', c('7',   '12',   '25',   '30',   '40',   '43'))\n",
    "node_gauges = OrderedDict([(node_ids[i], gauges[i]) for i in range(len(gauges))])\n",
    "# names(gauges) = node_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibNodes = paste0('node.', [\"7\",\"12\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "element_id = first(sub_cats)[0]\n",
    "element_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaugeId = [node_gauges[k] for k in calibNodes]\n",
    "gauge_flow = se_flows[gaugeId]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = sub_cats[element_id]\n",
    "parameteriser.apply_sys_config(sc)\n",
    "\n",
    "var_id = paste0(calibNodes, '.OutflowRate')\n",
    "simulation.record_state(var_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "objectiveId = 'NSE'\n",
    "\n",
    "def create_obj_station(i:int):\n",
    "    obs = as_xarray_series(gauge_flow[[gaugeId[i]]])\n",
    "    return simulation.create_objective(var_id[i], obs, objectiveId, xr_ts_start(se_flows), xr_ts_end(se_flows))\n",
    "\n",
    "objectives = [create_obj_station(i) for i in [0,1]]\n",
    "\n",
    "co = ObjectiveEvaluator.create_composite_objective(objectives, [1.0,1.0], var_id[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "score = co.get_score(parameteriser) \n",
    "# scoresAsDataFrame(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,eval,name,-all",
   "formats": "ipynb,py:percent",
   "main_language": "R"
  },
  "kernelspec": {
   "display_name": "hydrofc",
   "language": "python",
   "name": "hydrofc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
