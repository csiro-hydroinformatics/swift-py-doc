{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Getting started with the swift python package\n",
    "\n",
    "## About this document\n",
    "\n",
    "This is a minimal but realistic simulation workflow for swift. It was ported from an original [vignette](https://github.com/csiro-hydroinformatics/streamflow-forecasting-tools-onboard/blob/master/doc/vignettes/getting_started/getting_started.md) in the R package `swift`. The python package [`swift2`](https://csiro-hydroinformatics.github.io/swift-py-doc/) is, as of August 2023, at least at feature parity with the long established R package. \n",
    "\n",
    "This is the introduction 'notebook' to a python package for interacting with SWIFT. It shows one of the most basic usage, running a single model simulation. While basic, it is realistic and uses data from a study catchment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from swift2.doc_helper import pkg_versions_info\n",
    "\n",
    "print(pkg_versions_info(\"This document was generated from a jupyter notebook\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebook requires a working Python environment, e.g. a conda environment. See the [Streamflow Forecasting](https://csiro-hydroinformatics.github.io/streamflow-forecasting-tools-onboard/) landing page for information about installing the software.\n",
    "\n",
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Finally we import some visualisation facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Some dependencies of **swift2**, namely **cinterop**, offer generic functions for time series manipulations. While these could be imported via **swift2** as well, let's be explicit for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cinterop.timeseries import (\n",
    "    TIME_DIMNAME,\n",
    "    as_timestamp,\n",
    "    pd_series_to_xr_series,\n",
    "    slice_xr_time_series,\n",
    "    xr_ts_end,\n",
    "    xr_ts_start,\n",
    ")\n",
    "from swift2.doc_helper import get_free_params, sample_series\n",
    "from swift2.parameteriser import (\n",
    "    create_parameter_sampler,\n",
    "    create_parameteriser,\n",
    "    create_sce_termination_wila,\n",
    "    get_default_sce_parameters,\n",
    ")\n",
    "from swift2.simulation import create_subarea_simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from swift2.system import runoff_model_ids, runoff_model_var_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We import the main functions upfront from the package submodules. In practice this is something you may need to do only on an as needed basis of course. Jupyter notebooks can show dynanically submodules and functions listed, along with some documentation. A searchable technical documentation for the package is available from [Python swift2 documentation](https://csiro-hydroinformatics.github.io/swift-py-doc). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from swift2.utils import mk_full_data_id, paste_2, vpaste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Lumped catchment data, daily data\n",
    "\n",
    "The package contains some sample data for a few Australian catchments. Note that these sample data are for documentation only and not to be used for real world applications.  \n",
    "\n",
    "**swift** now has some functions to create a single subarea simulation for testing purposes, including the function `create_subarea_simulation`. While is it perfectly possible to manually build your own model simulation from scratch, for the sake of getting started quickly let's use pre-defined functions to get a model simulation ready to run. The parameters of the function should be fairly self-explanatory. But in general you can see function documentation with commands appended with the `?` string, e.g. `create_subarea_simulation?`. You can also browse the [Python swift2 documentation](https://csiro-hydroinformatics.github.io/swift-py-doc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_subarea_simulation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ms = create_subarea_simulation(data_id='MMH', simul_start='1990-01-01', simul_end='2005-12-31', \n",
    "    model_id='GR4J', tstep='daily', varname_rain='P', varname_pet='E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "The python object `ms` may appear unusual to most users. This is basically a handle to the SWIFT simulation object written in C++. The model core is native, but wrapped by a \"pythonic\" `Simulation` object. The low-level interaction between python and the C API is handled by \"glue code\" and users will rarely if ever need to use the low-level API.\n",
    "\n",
    "The `Simulation` object has python methods to interact with it, for instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ms.describe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ms.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Because we got a preconfigured, sample simulation, it is ready to execute, which means it already has some input data defined (a site with a codename 'MMH'). The `SWIFT` system uses the terms `playing from` and `recording to` time series, using an old style audio tape system as a metaphor. We can inspect the simulation for instance using `get_played_varnames` to check which state variable has an input time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ms.get_played_varnames()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Time series data representation\n",
    "\n",
    "Let us have a look at these input time series to the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tts = ms.get_played()\n",
    "tts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "The C++ core has its own internal representation of time series. The Python package `swift2` uses generally [`xarray`](https://docs.xarray.dev/en/stable/) to represent time series, as it is particularly suited to handle ensemble of time series of dimensionality more than 2. The ensemble dimension is thus present by default in the returned array, even when there is only one realisation. This can be removed with the [`squeeze`](https://docs.xarray.dev/en/stable/generated/xarray.DataArray.squeeze.html#xarray.DataArray.squeeze) method of xarray. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tts = tts.squeeze(drop=True)\n",
    "g = tts.plot.line(add_legend=True, figsize=(16,8), col=\"variable_identifiers\", col_wrap=1, sharey=False)\n",
    "g;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "\n",
    "Many `swift2` python functions will however also accept [pandas](https://pandas.pydata.org/docs/) `DataFrame` or `Series` as input for time series when it makes sense to accept such time series representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ms.play_input?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "We can check with the `get_recorded_varnames` method that simulation object as not been \"told\" to record an output time series yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ms.get_recorded_varnames()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "SWIFT is designed to record model variables on demand in a highly flexible manner. First, we can query the system to find out known rainfall-runoff models, and the model variable names that we can record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runoff_model_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "The GR4J model has the following states that can be \"listened to\" and \"recorded\" on demand over a simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gr4j_model_vars = runoff_model_var_ids('GR4J')\n",
    "print(gr4j_model_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "These are the variable names for a single GR4J model instance; since SWIFT is for semi-distributed models, we need to use a hierarchical naming scheme to uniquely identify model variables (even when in this case we do have only one subarea). Using unique keys allow to inspect the model states in great details if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ms.get_subarea_ids()\n",
    "ms.get_state_value('subarea.Subarea.x4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "\n",
    "Let's record to time series all the storage and flux states of GR4J (no need to record model parameters which will be flat lines here). We can use the utility function [`mk_full_data_id`](https://csiro-hydroinformatics.github.io/swift-py-doc/code-reference/?h=mk_full_data_id#swift2.utils.mk_full_data_id) for conciseness to vectorise the handling of multiple state identifiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_record = ['runoff', 'S', 'R', 'Ps', 'Es', 'Pr', 'ech1', 'ech2', 'Perc']\n",
    "ids = mk_full_data_id('subarea', 'Subarea', to_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ms.record_state(ids)\n",
    "ms.get_recorded_varnames()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "### Model execution\n",
    "\n",
    "`ms` was configured to record model outputs, now we can execute the simulation, with its parameters set to whatever defaults it has. Note that `ms` also has a `check_simulation` method that can provide information about  obvious configuration issues when execution fails. Typically inconstent start and end dates between simulation and input time series. In this case, nothing is reported in this simple and preconfigured case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms.check_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ms.exec_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "### Model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "var_series = ms.get_recorded()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "We have a 3 dimensional data array, with 9 identifiers for state variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "var_series.dims, var_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "var_coords = var_series.coords['variable_identifiers'].values\n",
    "var_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "The variable identifiers are fully qualified, which is fine and certainly make a lot of sense for semi-distributed catchments. But to visualise these for a single subarea we shall override with short model names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "var_series.coords['variable_identifiers'] = np.array([x.replace('subarea.Subarea.', \"\") for x in var_coords])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "### Visualising model states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "Let's look at a shorter period of the output. We define a couple of functions to slice and plot the last three years of the time series, for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def last_three_years(tts:xr.DataArray):\n",
    "    start=tts.coords[TIME_DIMNAME].values[-(365*3)]\n",
    "    end=tts.coords[TIME_DIMNAME].values[-1]\n",
    "    return slice_xr_time_series(tts, start, end)\n",
    "\n",
    "def plot_obs_vs_calc(obs, calc, ylab=\"runoff (mm)\"):\n",
    "    import uchronia.utils as uu\n",
    "    obs = last_three_years(obs)\n",
    "    calc = last_three_years(calc)\n",
    "    both = uu.xr_concat([obs,calc], ['observed','calculated'], 'type')\n",
    "    both.plot.line(add_legend=True, figsize=(9,4), hue=\"type\")\n",
    "    plt.ylabel(ylab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = last_three_years(var_series)\n",
    "# , main = 'Default GR4J output on MMH data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = s.squeeze(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = s.plot.line(add_legend=True, figsize=(16,16), col=\"variable_identifiers\", col_wrap=2, sharey=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "\n",
    "## Exploring the model interactively\n",
    "\n",
    "### Assessing a change in the input series\n",
    "\n",
    "As mentioned earlier, it is change to define the model simulation definition directly and interactively. The following shows how a to assign another input time series. We use a somewhat contrived example of a scaled up precipitation input series, to see what is the effect on the runoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "precip_id = 'subarea.Subarea.P'\n",
    "runoff_id = 'subarea.Subarea.runoff'\n",
    "precip = ms.get_played(precip_id)\n",
    "baseline_runoff = ms.get_recorded(runoff_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "Because we are about to work on a scenario, rather than modifying `ms` we are going to keep it as a clean baseline, and create a full \"clone\" of the catchment model. This is an understated feature of `swift2`, but a cornerstone of proper scenario comparison (and help limit modelling mistakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_wetter = ms.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "precip_scaled = precip * 1.1\n",
    "precip_scaled = precip_scaled.squeeze(drop=True)\n",
    "ms_wetter.play_input(precip_scaled, precip_id)\n",
    "ms_wetter.exec_simulation()\n",
    "runoff_diff = ms_wetter.get_recorded(runoff_id) - baseline_runoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runoff_diff = runoff_diff.squeeze(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "The additional runoff depth we get with a rainfall scaled up by 10 percent is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runoff_diff.plot(figsize=(9,4))\n",
    "plt.title('Change in runoff with precipitations scaled up by 10%')\n",
    "plt.ylabel('runoff depth change (mm/day)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "### Assessing the impact of a change in one model parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "x4_id = 'subarea.Subarea.x4'\n",
    "x4 = ms.get_state_value(x4_id)\n",
    "x4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "The returned value for $x_4$ is in a dictionary, because `get_state_value` is vectorised and can retrieve several state values at the same time. `set_state_value` on the other hand accepts multiple types of inputs including scalars for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "x4_inital = x4[x4_id]\n",
    "# Again, keep the baseline clean and work on a copy\n",
    "ms_x4 = ms.clone()\n",
    "\n",
    "ms_x4.set_state_value(x4_id, x4_inital*1.1)\n",
    "ms_x4.exec_simulation()\n",
    "runoff_diff = ms_x4.get_recorded(runoff_id) - baseline_runoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "One effect of $x_4$ is on the lagging effect, so the difference in runoff should be overall near zero, but with local variations:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "runoff_diff = runoff_diff.squeeze(drop=True)\n",
    "blah = last_three_years(runoff_diff).plot.line()\n",
    "plt.title('Change in runoff with x4 scaled up by 10%')\n",
    "plt.ylabel('runoff depth change (mm/day)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "\n",
    "## Calibration\n",
    "\n",
    "Let's now set up a calibration against the observed runoff depth for this data 'MMH', included as sample data in the package, and view it along the current default model runoff output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_runoff = sample_series('MMH', 'flow') #actually, runoff depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "Negative data in the observed streamflow is a code for missing data. It is better to use `np.nan` in Python for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_runoff[obs_runoff < -1] = np.nan\n",
    "obs_runoff = pd_series_to_xr_series(obs_runoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "Let's view the default modelled output from **GR4J**, overlayed with the observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_obs_vs_calc(obs_runoff, baseline_runoff.squeeze(drop=True));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "### Defining the calibration\n",
    "\n",
    "Before we go ahead in setting up this calibration, it is worth outlining key aspects of software architecture in `swift2` and its [metaheuristics optimisation library, \"wila\"](https://github.com/csiro-hydroinformatics/wila) upfront.\n",
    "\n",
    "At a high level a calibration process conceptually needs:\n",
    "\n",
    "* the specification of a feasible parameter space $X = x_1, x_2, ..., x_n$, typically with feasible intervals for each $x_i$\n",
    "* an objective evaluation $Obj(X)$\n",
    "* and an optimisation algorithm that uses $Obj$ and evaluates it on parameter values $X_p$ sampled from $X$\n",
    "\n",
    "Formulating a calibration in `swift2` follows this pattern. There is usually no need to explicitely handle the hydrological model, which is hidden behind $Obj$, and for some reasons this can be an unfamiliar viewpoint for many hydrologist.\n",
    "\n",
    "Readers interesting in modelling and optimisation framework design and implementation can read [Talbi, El-Ghazali. Metaheuristics: from design to implementation. John Wiley & Sons, 2009.](https://dl.acm.org/doi/abs/10.5555/1718024) for a comprehensive overview.\n",
    "\n",
    "Now let us see what these are in practice. \n",
    "\n",
    "**Note**: There are several time stamp representations in the Python ecosystem. A dependency package of the `swift2` package , **cinterop**, has a [time series module](https://cinterop.readthedocs.io/en/latest/timeseries-module/) with date-time and time series related utilities, such as `xr_ts_start`, `as_timestamp` to reduce the tedium of date-time handling. You may also already be using third-party utilities as well. \n",
    "\n",
    "#### Objective\n",
    "\n",
    "Part of the information for the objective is over which time span we calculate the goodness of fit, usually different from the simulation length to leave period for a model warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "s = xr_ts_start(obs_runoff)\n",
    "# Warmup:\n",
    "w = as_timestamp(s) + pd.DateOffset(years=2)\n",
    "e = xr_ts_end(obs_runoff)\n",
    "ms.set_simulation_span(s, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "We now have all the information needed to create a calibration objective using for instance the Nash-Sutcliffe Efficiency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = ms.create_objective(runoff_id, obs_runoff, 'NSE', w, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "The variable `objective` now references an objective evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(objective), objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "An objective evaluator evaluates one or more goodness of fit (a.k.a. \"scores\") via the method `objective.get_score`. We need to provide a set of model parameters to evaluate the resulting scores. The utility function `get_free_params` provides a template for some models including **GR4J**, in the form of a pandas DataFrame\n",
    "\n",
    "#### Feasible parameter space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pspec_gr4j = get_free_params('GR4J')\n",
    "pspec_gr4j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "We can set some values and min/max bounds in this data frame. The min/max bounds are important for the upcoming calibration process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pspec_gr4j.Value = [542.1981111,  -0.4127542,   7.7403390 ,  1.2388548]\n",
    "pspec_gr4j.Min = [1,-30, 1,1]\n",
    "pspec_gr4j.Max = [1000.0, 30, 1000, 240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pspec_gr4j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "Our model states have the prefix 'subarea.Subarea.', so we need to use this prefix in our data frame of parameters as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pspec_gr4j.Name = vpaste('subarea.Subarea.', pspec_gr4j.Name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88",
   "metadata": {},
   "source": [
    "We can now create a parameteriser. It can be converted back to a data frame to check its content.\n",
    "\n",
    "**Note**: we will be using the untransformed parameters for calibration for the sake of simplicity in this introductory material. In practice we should use some transformations to facilitate the calibration, and there are many features in **swift2** to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = create_parameteriser('Generic', pspec_gr4j)\n",
    "p.as_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "Now let us check that we can indeed evaluate the goodness of fit for this parameteriser `p` using the `objective`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = objective.get_score(p)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "Our calibration objective calculator is structurally valid.\n",
    "\n",
    "#### Optimiser\n",
    "\n",
    "To create an optimiser, we need to specify a termination criterion. There are several options available to control when an optimisation process will finish in a calibration. One of them uses the standard deviation of parameter values for population based algorithms such as the shuffled complex evolution algorithm (SCE). We can specify that the optimisation has converged once the standard deviation of each parameter (x1, x2, etc. for GR4J) is within "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "term = create_sce_termination_wila('relative standard deviation', ['0.002','0.0167'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "sce_params = get_default_sce_parameters()\n",
    "urs = create_parameter_sampler(0, p, 'urs')\n",
    "optimiser = objective.create_sce_optim_swift(term, sce_params, urs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser.set_calibration_logger('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calib_results = optimiser.execute_optimisation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97",
   "metadata": {},
   "source": [
    "**swift** uses optimization tools that will parallelize model simulation runs if possible (i.e. if supported by the model). This may not be noticeable in this instance, but is important to scale up to larger catchment models. \n",
    "\n",
    "## Assessing the optimisation\n",
    "\n",
    "There are facilities in the package to extract, exploit and visualise the optimisation log information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_log = optimiser.extract_optimisation_log(fitness_name = \"NSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_log.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_log.data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "Let's subset the data points to keep a subset, the points from the initial population and SCE geometric transformations (reflection, contraction, addition). We can use a regular expression pattern to do so. `MhData` is a glorified data frame, but its methods are handy to reduce tedium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_ops = opt_log.subset_by_message(pattern= 'Initial.*|Reflec.*|Contrac.*|Add.*') # same as default argument, but to be explicit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "Let us also rename the column names without the fully qualified prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_var_ids = ['x1','x2','x3','x4']\n",
    "remap = {f'subarea.Subarea.{name}': name for name in p_var_ids}\n",
    "geom_ops.rename_columns(remap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105",
   "metadata": {},
   "source": [
    "### Visualising the optimisation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from swift2.vis import OptimisationPlots\n",
    "\n",
    "v = OptimisationPlots(geom_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107",
   "metadata": {},
   "source": [
    "We can see that at least one of the parameters, namely \"x1\", settled at its upper boundary of 1000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = v.parameter_evolution(p_var_ids[0], obj_lims=[0,1])\n",
    "plt.gcf().set_size_inches(10,8);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109",
   "metadata": {},
   "source": [
    "Note that the parameter x4 also seems to have settled at its lower bound:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.parameter_evolution(p_var_ids[3], obj_lims=[0,1])\n",
    "plt.gcf().set_size_inches(10,8);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111",
   "metadata": {},
   "source": [
    "x4 influences the unit hydrograph, and the meaning of this parameter depends on the time step of the input series. It may be justified in this case to go below 1 for its lower bound. Also, the default maximum value 240 is typically sensible for use with hourly data, not daily, so we may want to reduce this maximum. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112",
   "metadata": {},
   "source": [
    "So let's restart the calibration, with a larger upper bound for the x1 parameter, and adjusted x4 bounds as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "pspec_gr4j.Max = [2500, 30, 1000, 10]\n",
    "pspec_gr4j.Min = [1,-30, 1,0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = create_parameteriser('Generic', pspec_gr4j)\n",
    "urs = create_parameter_sampler(0, p, 'urs')\n",
    "optimiser = objective.create_sce_optim_swift(term, sce_params, urs)\n",
    "calib_logger = optimiser.set_calibration_logger('')\n",
    "calib_results = optimiser.execute_optimisation()\n",
    "opt_log = optimiser.extract_optimisation_log(fitness_name = \"NSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_ops = opt_log.subset_by_message(pattern= 'Initial.*|Reflec.*|Contrac.*|Add.*') # same as default argument, but to be explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_var_ids = ['x1','x2','x3','x4']\n",
    "remap = {f'subarea.Subarea.{name}': name for name in p_var_ids}\n",
    "geom_ops.rename_columns(remap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117",
   "metadata": {},
   "source": [
    "Let's check that the parameter does not settle at the boundary anymore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = OptimisationPlots(geom_ops)\n",
    "g = v.parameter_evolution(p_var_ids[0], obj_lims=[0,1])\n",
    "plt.gcf().set_size_inches(10,8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.parameter_evolution(p_var_ids[3], obj_lims=[0,1])\n",
    "plt.gcf().set_size_inches(10,8);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120",
   "metadata": {},
   "source": [
    "_Note_: There are a few additional visualisation options in the R package [**mhplot**](https://github.com/csiro-hydroinformatics/mhplot) that may be ported to python as needed.\n",
    "\n",
    "We can inspect further the behavior of the SCE optimiser by using facetted plots with the package **seaborn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = geom_ops.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = geom_ops.facet_plot(p_var_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123",
   "metadata": {},
   "source": [
    "Let's retrieve the parameter set with the best NSE, and see the resulting runoff time series. `calib_results` is a native C++ object, but its wrapper has functions to query it and extract the information wanted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124",
   "metadata": {},
   "source": [
    "`calib_results` is the final population of parameter sets. To get the best score within it (i.e. the best fitness and associated parameters), we can use: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pset = calib_results.get_best_score('NSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_log.data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128",
   "metadata": {},
   "source": [
    "## Time series visualisation\n",
    "\n",
    "Let's apply this parameter to the original simulation, and execute it to get output runoff.\n",
    "\n",
    "Note, as an aside, that below for didactic purposes we see only the last 3 years of time series, while the NSE score is calculated over several more years. As it happens, the runoff prediction has a systematic negative bias over these three particular years.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pset.apply_sys_config(ms)\n",
    "ms.exec_simulation()\n",
    "plot_obs_vs_calc(obs_runoff, ms.get_recorded(runoff_id).squeeze(drop=True))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130",
   "metadata": {},
   "source": [
    "Looking at the whole series over the simulation, indeed these last three years appear untypical in terms of match between observed and calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from swift2.vis import plot_two_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_series(obs_runoff, ms.get_recorded(runoff_id).squeeze(drop=True), names = ['observed','calculated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "hydrofc",
   "language": "python",
   "name": "hydrofc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
