{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "source": [
    "# Calibration of a catchment using multisite multiobjective composition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## About this document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from swift2.doc_helper import pkg_versions_info\n",
    "\n",
    "print(pkg_versions_info(\"This document was generated from a jupyter notebook\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Use case\n",
    "\n",
    "This vignette demonstrates how one can calibrate a catchment using multiple gauging points available within this catchment. This only covers the definition of the calibration, **not the execution**. The sample data in the package is a small subset of hourly data to keep things (data size, execution time) small.\n",
    "\n",
    "This is a joint calibration weighing multiple objectives, possibly sourced from different modelling objects in the semi-distributed structure, thus a whole-of-catchment calibration technique. A staged, cascading calibration is supported and described in another vignette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from swift2.utils import mk_full_data_id\n",
    "from swift2.classes import CompositeParameteriser, HypercubeParameteriser, Simulation\n",
    "# from swift2.wrap.ffi_interop import debug_msd\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import swift2.doc_helper as std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cinterop.timeseries import TIME_DIMNAME, slice_xr_time_series, pd_series_to_xr_series, slice_xr_time_series, pd_series_to_xr_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cinterop.timeseries import xr_ts_start, xr_ts_end\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The sample data that comes with the package contains a model definition for the South Esk catchment, including a short subset of the climate and flow record data.\n",
    "\n",
    "<img src=\"south_esk.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "<!-- ![](./south_esk.png)\n",
    " -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'GR4J'\n",
    "site_id = 'South_Esk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "se_climate = std.sample_series(site_id=site_id, var_name='climate')\n",
    "se_flows = std.sample_series(site_id=site_id, var_name='flow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "se_climate.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "se_climate.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Base model creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation = std.sample_catchment_model(site_id=site_id, config_id='catchment')\n",
    "# simulation = swap_model(simulation, 'MuskingumNonLinear', 'channel_routing')\n",
    "simulation = simulation.swap_model('LagAndRoute', 'channel_routing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "The names of the climate series is already set to the climate input identifiers of the model simulation, so setting them as inputs is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation.play_input(se_climate)\n",
    "simulation.set_simulation_span(xr_ts_start(se_climate), xr_ts_end(se_climate))\n",
    "simulation.set_simulation_time_step('hourly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Moving on to define the parameters, free or fixed. We will use (for now - may change) the package calibragem, companion to SWIFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "std.configure_hourly_gr4j(simulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Parameterisation\n",
    "\n",
    "We define a function creating a realistic feasible parameter space. The parameteriser is relatively sophisticated, but this is not the main purpose of this vignette, so we do not describe the process about defining and creating parameterisers in gread details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from swift2.utils import c, paste0, rep\n",
    "import swift2.parameteriser as sp\n",
    "import swift2.helpers as hlp\n",
    "\n",
    "\n",
    "def create_meta_parameteriser(simulation:Simulation, ref_area=250, time_span=3600):  \n",
    "    time_span = int(time_span)\n",
    "    parameteriser = std.define_gr4j_scaled_parameter(ref_area, time_span)\n",
    "  \n",
    "    # Let's define _S0_ and _R0_ parameters such that for each GR4J model instance, _S = S0 * x1_ and _R = R0 * x3_\n",
    "    p_states = sp.linear_parameteriser(\n",
    "                      param_name=c(\"S0\",\"R0\"), \n",
    "                      state_name=c(\"S\",\"R\"), \n",
    "                      scaling_var_name=c(\"x1\",\"x3\"),\n",
    "                      min_p_val=c(0.0,0.0), \n",
    "                      max_p_val=c(1.0,1.0), \n",
    "                      value=c(0.9,0.9), \n",
    "                      selector_type='each subarea')\n",
    "  \n",
    "    init_parameteriser = p_states.make_state_init_parameteriser()\n",
    "    parameteriser = sp.concatenate_parameterisers(parameteriser, init_parameteriser)\n",
    "    \n",
    "    hlp.lag_and_route_linear_storage_type(simulation)\n",
    "    hlp.set_reach_lengths_lag_n_route(simulation)\n",
    "\n",
    "    lnrp = hlp.parameteriser_lag_and_route()\n",
    "    parameteriser = CompositeParameteriser.concatenate(parameteriser, lnrp, strategy='')\n",
    "    return parameteriser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameteriser = create_meta_parameteriser(simulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "We have built a parameteriser for jointly parameterising:\n",
    "\n",
    "* GR4J parameters in transformed spaces ($log$ and $asinh$)\n",
    "* GR4J initial soil moisture store conditions ($S_0$ and $R_0$)\n",
    "* A \"lag and route\" streamflow routing scheme in transform space.\n",
    "\n",
    "There is even more happening there, because on top of GR4J parameter transformation we scale some in proportion to catchment area and time step length. But this is besides the point of this vignette: refer for instance to the vignette about tied parameters to know more about parameter transformation and composition of parameterisers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameteriser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Let us check that we can apply the parameteriser and use its methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameteriser.set_parameter_value('asinh_x2', 0)\n",
    "parameteriser.apply_sys_config(simulation)\n",
    "simulation.exec_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "We are now ready to enter the main topic of this vignette, i.e. setting up a weighted multi-objective for calibration purposes.\n",
    "\n",
    "## Defining weighting multi-objectives\n",
    "\n",
    "The sample gauge data flow contains gauge identifiers as column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "se_flows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "The network of nodes of the simulation is arbitrarily identified with nodes '1' to '43'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation.describe()[\"nodes\"].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "We \"know\" that we can associate the node identifiers 'node.{i}' with gauge identifiers (note to doc maintainers: manually extracted from legacy swiftv1 NodeLink files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauges = c( '92106', '592002', '18311', '93044',    '25',   '181')\n",
    "node_ids = paste0('node.', c('7',   '12',   '25',   '30',   '40',   '43'))   \n",
    "# names(gauges) = node_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "First, let us try the Nash Sutcliffe efficiency, for simplicity (no additional parameters needed). We will set up NSE calculations at two points (nodes) in the catchments. Any model state from a link, node or subarea could be a point for statistics calculation.\n",
    "\n",
    "The function `multi_statistic_definition` in the module `swift2.statistics` is used to create multisite multiobjective definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import swift2.statistics as ssf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssf.multi_statistic_definition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "span = simulation.get_simulation_span()\n",
    "span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = span['start']\n",
    "e = span['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_points = node_ids[:2]\n",
    "mvids = mk_full_data_id(calibration_points, 'OutflowRate')\n",
    "mvids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "statspec = ssf.multi_statistic_definition( \n",
    "  model_var_ids = mvids, \n",
    "  statistic_ids = rep('nse', 2), \n",
    "  objective_ids = calibration_points, \n",
    "  objective_names = paste0(\"NSE-\", calibration_points), \n",
    "  starts = [s, s + pd.DateOffset(hours=3)],\n",
    "  ends =  [e + pd.DateOffset(hours=-4), e + pd.DateOffset(hours=-2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "We now have our set of statistics defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "statspec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "To create a multisite objective evaluator we need to use the `create_multisite_objective` method of the `simulation` object. We have out statistics defined. The method requires observations and weights to give to combine statistics to a single objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation.create_multisite_objective?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = [\n",
    "  se_flows[gauges[0]],\n",
    "  se_flows[gauges[1]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = {calibration_points[0]: 1.0, calibration_points[1]: 2.0} # weights (internally normalised to a total of 1.0)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "moe = simulation.create_multisite_objective(statspec, observations, w)\n",
    "moe.get_score(parameteriser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "We can get the value of each objective. The two NSE scores below are negative. Note above that the composite objective is positive, i.e. the opposite of the weighted average. This is because the composite objective is always minimisable (as of writing anyway this is a design choice.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "moe.get_scores(parameteriser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "## log-likelihood multiple objective\n",
    "\n",
    "Now, let's move on to use log-likelihood instead of NSE. This adds one level of complexity compared to the above. Besides calibrating the hydrologic parameters of GR4J and flow routing, with the Log-Likelihood we introduce a set of parameters $(a, b, m, s, ...)$ for each calibration point. The statistic definition is similar and still straightforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "statspec = ssf.multi_statistic_definition(  \n",
    "  model_var_ids = mvids, \n",
    "  statistic_ids = rep('log-likelihood', 2), \n",
    "  objective_ids=calibration_points, \n",
    "  objective_names = paste0(\"LL-\", calibration_points), \n",
    "  starts = rep(span['start'], 2), \n",
    "  ends = rep(span['end'], 2) )\n",
    "\n",
    "statspec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "But while we can create the calculator, we cannot evaluate it against the sole hydrologic parameters defined in the previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = simulation.create_multisite_objective(statspec, observations, w)\n",
    "### This cannot work if the statistic is the log-likelihood:\n",
    "# obj.get_scores(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "If we try to do the above we would end up with an error message 'Mandatory key expected in the dictionary but not found: b'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "For this to work we need to include parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxobs = np.max(observations[0].values) # NOTE: np.nan??\n",
    "censor_threshold = 0.01\n",
    "censopt = 0.0\n",
    "calc_m_and_s = 1.0 # i.e. TRUE\n",
    "\n",
    "#\t\tconst string LogLikelihoodKeys::KeyAugmentSimulation = \"augment_simulation\";\n",
    "#\t\tconst string LogLikelihoodKeys::KeyExcludeAtTMinusOne = \"exclude_t_min_one\";\n",
    "#\t\tconst string LogLikelihoodKeys::KeyCalculateModelledMAndS = \"calc_mod_m_s\";\n",
    "#\t\tconst string LogLikelihoodKeys::KeyMParMod = \"m_par_mod\";\n",
    "#\t\tconst string LogLikelihoodKeys::KeySParMod = \"s_par_mod\";\n",
    "\n",
    "p = sp.create_parameteriser('no apply')\n",
    "# Note: exampleParameterizer is also available\n",
    "p.add_to_hypercube( \n",
    "          pd.DataFrame.from_dict( dict(Name=c('b','m','s','a','maxobs','ct', 'censopt', 'calc_mod_m_s'),\n",
    "          Min   = c(-30, 0, 1,    -30, maxobs, censor_threshold, censopt, calc_m_and_s),\n",
    "          Max   = c(0,   0, 1000, 1, maxobs, censor_threshold, censopt, calc_m_and_s),\n",
    "          Value = c(-7,  0, 100,  -10, maxobs, censor_threshold, censopt, calc_m_and_s)) ))\n",
    "\n",
    "p.as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_parameterisers = [p, p.clone()] # for the two calib points, NSE has no param here\n",
    "catchment_pzer = parameteriser\n",
    "fp = sp.create_multisite_obj_parameteriser(func_parameterisers, calibration_points, prefixes=paste0(calibration_points, '.'), mix_func_parameteriser=None, hydro_parameteriser=catchment_pzer)\n",
    "fp.as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "moe = obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "To get the overall weighted multiobjective score (for which lower is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "moe.get_score(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "To get each individual log-likelihood scores for each gauge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "moe.get_scores(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,eval,name,-all",
   "formats": "ipynb,py:percent",
   "main_language": "R"
  },
  "kernelspec": {
   "display_name": "hydrofc",
   "language": "python",
   "name": "hydrofc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
